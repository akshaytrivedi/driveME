{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_101_FPN_PATH = \"/home/at3577/driveME/src/fair-maskrcnn/models/35861858-R-101-FPN/model_final.pkl\"\n",
    "X_152_32x8d_FPN_IN5k_PATH = \"/home/at3577/driveME/src/fair-maskrcnn/models/37129812-X-152-32x8d-FPN-IN5k/model_final.pkl\"\n",
    "R_101_PATH = \"/home/at3577/driveME/src/fair-maskrcnn/models/R-101/R-101.pkl\"\n",
    "X_152_32x8d_IN5k_PATH = \"/home/at3577/driveME/src/fair-maskrcnn/models/X-152-32x8d-IN5k/X-152-32x8d-IN5k.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self, resnet_feature_extraction_layers=['conv1','bn1','relu','maxpool','layer1','layer2','layer3']):\n",
    "        super(ResnetModel, self).__init__()\n",
    "        \n",
    "        self.resnet_model = eval('models.resnet101()') # construct ResNet model (maybe not very safe :) \n",
    "\n",
    "        # swap stride (2,2) and (1,1) in first layers (PyTorch ResNet is slightly different to caffe2 ResNet)\n",
    "        # this is required for compatibility with caffe2 models\n",
    "        self.resnet_model.layer2[0].conv1.stride=(2,2)\n",
    "        self.resnet_model.layer2[0].conv2.stride=(1,1)\n",
    "        self.resnet_model.layer3[0].conv1.stride=(2,2)\n",
    "        self.resnet_model.layer3[0].conv2.stride=(1,1)\n",
    "        self.resnet_model.layer4[0].conv1.stride=(2,2)\n",
    "        self.resnet_model.layer4[0].conv2.stride=(1,1)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        # All except the last layer are used as feature extractor... Last layer is for ROI pooling\n",
    "        self.model = torch.nn.Sequential(*[getattr(self.resnet_model, layer) for layer in resnet_feature_extraction_layers])\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.model(image)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with open(R_101_FPN_PATH, 'rb') as model_pickle_file:\n",
    "            fb_model = pickle.load(model_pickle_file)\n",
    "            # Model has two keys- config and blobs\n",
    "            fb_model = fb_model['blobs']\n",
    "        \n",
    "        model_dict = self.resnet_model.state_dict()\n",
    "        \n",
    "        for key in model_dict.keys():\n",
    "            # skip running mean/std and fc weights\n",
    "            # I am not sure what running is but fc is the last fuly connected layer of resnet.. so fb model doesnt have it\n",
    "            if 'running' in key or 'fc' in key:\n",
    "                continue\n",
    "            \n",
    "            fb_key = self.convert_key_to_fb_format(key.split('.'))\n",
    "           \n",
    "            assert model_dict[key].size()==torch.FloatTensor(fb_model[fb_key]).size()\n",
    "            \n",
    "            if key=='conv1.weight': # convert from BGR to RGB                \n",
    "                model_dict[key]=torch.FloatTensor(fb_model[fb_key][:,(2, 1, 0),:,:])\n",
    "            else:\n",
    "                model_dict[key]=torch.FloatTensor(fb_model[fb_key])\n",
    "        \n",
    "        # update model\n",
    "        self.resnet_model.load_state_dict(model_dict)\n",
    "\n",
    "    def convert_key_to_fb_format(self, terms, i=0, parsed=''):\n",
    "        # Convert PyTorch ResNet weight names to caffe2 weight names\n",
    "        if i==0:\n",
    "            if terms[i]=='conv1':\n",
    "                parsed='conv1'\n",
    "            elif terms[i]=='bn1':\n",
    "                parsed='res_conv1'\n",
    "            elif terms[i].startswith('layer'):\n",
    "                parsed='res'+str(int(terms[i][-1])+1)\n",
    "        else:\n",
    "            if terms[i]=='weight' and (terms[i-1].startswith('conv') or terms[i-1]=='0'):\n",
    "                parsed+='_w'\n",
    "            elif terms[i]=='weight' and (terms[i-1].startswith('bn') or terms[i-1]=='1'):\n",
    "                parsed+='_bn_s'\n",
    "            elif terms[i]=='bias' and (terms[i-1].startswith('bn') or terms[i-1]=='1'):\n",
    "                parsed+='_bn_b'\n",
    "            elif terms[i-1].startswith('layer'):\n",
    "                parsed+='_'+terms[i]\n",
    "            elif terms[i].startswith('conv') or terms[i].startswith('bn'):\n",
    "                parsed+='_branch2'+chr(96+int(terms[i][-1]))\n",
    "            elif terms[i]=='downsample':\n",
    "                parsed+='_branch1'\n",
    "        # increase counter\n",
    "        i+=1\n",
    "        # do recursion\n",
    "        if i==len(terms):\n",
    "            return parsed\n",
    "        return self.convert_key_to_fb_format(terms,i,parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RegionProposalNetwork(nn.Module):\n",
    "    def __init__(self, feature_extractor_output_channels, rpn_conv_output_channels, number_of_anchors):\n",
    "        super(RegionProposalNetwork, self).__init__()\n",
    "        \n",
    "        #RPN is used propose regions with probability of foreground/background.. i.e just tell if object is present\n",
    "        # It has 3 parts:\n",
    "        # 1) 3x3 conv with 512/1024 channels\n",
    "        # 2) 1x1 conv with 2k channels (for each anchor box we predict foreground/background)\n",
    "        # 3) 1x1 conv with 4k channels (for each anchor box we predict delta of boxes)\n",
    "        \n",
    "        self.conv_rpn = torch.nn.Conv2d(in_channels=feature_extractor_output_channels,\n",
    "                                        out_channels=rpn_conv_output_channels,\n",
    "                                        filter=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "        self.rpn_cls_prob = torch.nn.Conv2d(rpn_conv_output_channels,number_of_anchors,1,stride=1,padding=0)\n",
    "        self.rpn_bbox_pred = torch.nn.Conv2d(rpn_conv_output_channels,4*number_of_anchors,1,stride=1,padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
