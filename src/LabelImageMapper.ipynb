{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/at3577/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.python.framework.ops import convert_to_tensor\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_images_list = [\"road01_cam_6_video_18_image_list_train.txt\", \"road01_cam_5_video_18_image_list_train.txt\"]\n",
    "train_dataframe = pd.DataFrame([])\n",
    "for filename in os.listdir('/scratch/at3577/cvpr/train_video_list/'):\n",
    "    if filename.endswith('.txt') and filename not in missing_images_list:\n",
    "        dataframe = pd.read_csv(os.path.join('/scratch/at3577/cvpr/train_video_list/', filename), delimiter=r\"\\s+\", header=None)\n",
    "        dataframe[1] = dataframe.apply(lambda row : row[1].split('\\\\')[-1], axis=1)\n",
    "        dataframe[1] = dataframe.apply(lambda row : os.path.join('/scratch/at3577/cvpr/train_color/',row[1]), axis=1)\n",
    "        \n",
    "        dataframe[3] = dataframe.apply(lambda row : row[3].split('\\\\')[-1], axis=1)\n",
    "        dataframe[3] = dataframe.apply(lambda row : os.path.join('/scratch/at3577/cvpr/train_label/',row[3]), axis=1)\n",
    "        train_dataframe = train_dataframe.append(dataframe[[1,3]])\n",
    "\n",
    "train_dataframe.columns =['image','ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_mapping_dataframe = train_dataframe\n",
    "image_paths, ground_truth_paths = image_mapping_dataframe.as_matrix()[:,0] ,image_mapping_dataframe.as_matrix()[:,1]\n",
    "\n",
    "# create dataset\n",
    "ground_truth_paths = convert_to_tensor(ground_truth_paths, dtype=tf.string)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ground_truth_paths)\n",
    "num_of_ground_truths = len(image_mapping_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _map_filenames_to_image(ground_truth_filename):\n",
    "    ground_truth_string = tf.read_file(ground_truth_filename)\n",
    "    ground_truth_decoded = tf.image.decode_png(ground_truth_string, channels=0, dtype=tf.uint16)\n",
    "    return ground_truth_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _map_image_to_labels(ground_truth):\n",
    "    labels = tf.div(ground_truth, 1000)\n",
    "    labels = tf.reshape(labels,[-1])\n",
    "    labels, _ = tf.unique(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func=_map_filenames_to_image, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func=_map_image_to_labels, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "next_batch = iterator.get_next()\n",
    "iterator_init_op = iterator.make_initializer(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_image_map = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start Tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator_init_op)\n",
    "    \n",
    "    for i in range(num_of_ground_truths):\n",
    "        try:\n",
    "            image_filename = image_mapping_dataframe.iloc[i,0]\n",
    "            ground_truth_filename = image_mapping_dataframe.iloc[i,1]\n",
    "            ground_truth = sess.run(next_batch)\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            print 'Error for image file= ' + image_filename + ' groundtruth file= ' + ground_truth_filename\n",
    "        \n",
    "        for label in ground_truth:\n",
    "            if label != 0:\n",
    "                if label not in label_to_image_map:\n",
    "                    label_to_image_map[label] = []\n",
    "                label_to_image_map[label].append(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/scratch/at3577/cvpr/label_to_image_map.pkl', 'wb') as f:\n",
    "    pickle.dump(label_to_image_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SPLITTING DATA FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = open('/scratch/at3577/cvpr/label_to_image_map.pkl','r')\n",
    "label_to_image_map = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 34, 35, 36, 37, 38, 65, 40, 39]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_image_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key= 33 Values= 37682\n",
      "Key= 34 Values= 7661\n",
      "Key= 35 Values= 9116\n",
      "Key= 36 Values= 22228\n",
      "Key= 37 Values= 3860\n",
      "Key= 38 Values= 14255\n",
      "Key= 65 Values= 30906\n",
      "Key= 40 Values= 8702\n",
      "Key= 39 Values= 18265\n"
     ]
    }
   ],
   "source": [
    "for key in label_to_image_map.keys():\n",
    "    print 'Key= ' + str(key) + ' Values= ' + str(len(label_to_image_map[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_image_map_val = dict()\n",
    "val_set = set()\n",
    "for key in label_to_image_map.keys():\n",
    "    if key != 65:\n",
    "        label_to_image_map_val[key] = label_to_image_map[key][0:500]\n",
    "        val_set.update(label_to_image_map_val[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_to_image_map_train = dict()\n",
    "training_set = set()\n",
    "for key in label_to_image_map.keys():\n",
    "    label_to_image_map_train[key] = []\n",
    "    \n",
    "    for filename in label_to_image_map[key]:\n",
    "        if filename not in val_set:\n",
    "            label_to_image_map_train[key].append(filename)\n",
    "    \n",
    "    training_set.update(label_to_image_map_train[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2759"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36215"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38974"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set) + len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key= 33 Train Values= 35098 Val Values= 500\n",
      "Key= 34 Train Values= 6981 Val Values= 500\n",
      "Key= 35 Train Values= 8372 Val Values= 500\n",
      "Key= 36 Train Values= 20588 Val Values= 500\n",
      "Key= 37 Train Values= 3360 Val Values= 500\n",
      "Key= 38 Train Values= 13355 Val Values= 500\n",
      "Key= 39 Train Values= 16321 Val Values= 500\n",
      "Key= 40 Train Values= 7594 Val Values= 500\n"
     ]
    }
   ],
   "source": [
    "for key in label_to_image_map_test.keys():\n",
    "    print 'Key= ' + str(key) + ' Train Values= ' + str(len(label_to_image_map_train[key])) + ' Val Values= ' + str(len(label_to_image_map_val[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/scratch/at3577/cvpr/label_to_image_map_train.pkl', 'wb') as f:\n",
    "    pickle.dump(label_to_image_map_train, f)\n",
    "\n",
    "with open('/scratch/at3577/cvpr/label_to_image_map_val.pkl', 'wb') as f:\n",
    "    pickle.dump(label_to_image_map_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/scratch/at3577/cvpr/train_image_list.pkl', 'wb') as f:\n",
    "    pickle.dump(list(training_set), f)\n",
    "\n",
    "with open('/scratch/at3577/cvpr/val_image_list.pkl', 'wb') as f:\n",
    "    pickle.dump(list(val_set), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
